#!/usr/bin/env python3
"""
CS1Profiler CSV Analysis Tool
Cities: Skylines 1 ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ã®CSVãƒ‡ãƒ¼ã‚¿ã‚’è§£æãƒ»å¯è¦–åŒ–ã™ã‚‹ãƒ„ãƒ¼ãƒ«
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆWindowsç’°å¢ƒå¯¾å¿œï¼‰
plt.rcParams['font.family'] = ['DejaVu Sans', 'Yu Gothic', 'Hiragino Sans', 'Noto Sans CJK JP']
plt.rcParams['figure.figsize'] = (12, 8)

class CS1ProfilerAnalyzer:
    def __init__(self, csv_file):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§åˆæœŸåŒ–"""
        self.csv_file = csv_file
        self.df = None
        self.load_data()
    
    def load_data(self):
        """CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆPhase2ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œï¼‰"""
        try:
            self.df = pd.read_csv(self.csv_file)
            
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè‡ªå‹•æ¤œå‡º
            columns = self.df.columns.tolist()
            print(f"ğŸ” æ¤œå‡ºã—ãŸåˆ—: {columns}")
            
            if 'EventType' in columns and 'Rank' in columns:
                # å¤ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆPhase0ï¼‰
                print("ğŸ“Š æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
                method_name_col = 'Description'
            elif 'EventType' not in columns and 'Rank' not in columns and 'DateTime' in columns:
                # Phase2ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                print("ğŸ“Š Phase2ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
                method_name_col = 'Description'
            elif 'FrameCount' in columns:
                # è»½é‡åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆFrameCountæœ‰ã‚Šï¼‰
                print("ğŸ“Š è»½é‡åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆFrameCountï¼‰æ¤œå‡º")
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚«ã‚¦ãƒ³ãƒˆã‹ã‚‰ãŠãŠã‚ˆãã®æ™‚é–“ã‚’æ¨å®šï¼ˆ60FPSã¨ä»®å®šï¼‰
                self.df['DateTime'] = pd.to_datetime('2024-01-01') + pd.to_timedelta(self.df['FrameCount'] / 60.0, unit='s')
                method_name_col = 'MethodName'
            elif 'Timestamp' in columns and 'MethodName' in columns:
                # æ–°MPSC ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆTimestampæœ‰ã‚Šï¼‰
                print("ğŸ“Š æ–°MPSCãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
                # Timestampåˆ—ã‚’DateTimeå½¢å¼ã«å¤‰æ›
                self.df['DateTime'] = pd.to_datetime(self.df['Timestamp'])
                method_name_col = 'MethodName'
                # Countåˆ—ãŒãªã„å ´åˆã¯1ã¨ã—ã¦æ‰±ã†
                if 'Count' not in self.df.columns:
                    self.df['Count'] = 1
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                print("ğŸ“Š ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
                method_name_col = 'Description'
            
            # DateTimeåˆ—ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å¤‰æ›
            if 'DateTime' in self.df.columns:
                self.df['DateTime'] = pd.to_datetime(self.df['DateTime'])
            
            # TotalDurationPerFrameåˆ—ã®ä½œæˆ
            if 'Count' in self.df.columns:
                self.df['TotalDurationPerFrame'] = self.df['Duration(ms)'] * self.df['Count']
            else:
                self.df['TotalDurationPerFrame'] = self.df['Duration(ms)']
                
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.df)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            if 'DateTime' in self.df.columns:
                print(f"ğŸ“… æœŸé–“: {self.df['DateTime'].min()} ï½ {self.df['DateTime'].max()}")
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæƒ…å ±ã‚’è¡¨ç¤º
            if 'FrameCount' in self.df.columns:
                print(f"ğŸ® ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²: {self.df['FrameCount'].min()} ï½ {self.df['FrameCount'].max()}")
            else:
                print(f"â±ï¸ æ™‚é–“ç¯„å›²: {self.df['DateTime'].min()} ï½ {self.df['DateTime'].max()}")
            
            # ãƒ¡ã‚½ãƒƒãƒ‰åã‚«ãƒ©ãƒ ã‚’çµ±ä¸€
            if method_name_col != 'Description':
                self.df['Description'] = self.df[method_name_col]
            
        except Exception as e:
            print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def method_statistics(self, spike_multiplier=2.0):
        """ãƒ¡ã‚½ãƒƒãƒ‰åˆ¥çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ"""
        print("\nğŸ“Š ãƒ¡ã‚½ãƒƒãƒ‰åˆ¥çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆä¸­...")
        
        method_stats = []
        
        for method_name, method_data in self.df.groupby('Description'):
            durations = method_data['Duration(ms)']
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ã¦ï¼‰
            if 'FrameCount' in self.df.columns:
                frame_totals = method_data.groupby('FrameCount')['TotalDurationPerFrame'].sum()
                frame_calls = method_data.groupby('FrameCount')['Count'].sum()
            else:
                # æ–°MPSCãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã¯æ™‚é–“è»¸ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                method_data['TimeGroup'] = method_data['DateTime'].dt.floor('1S')  # 1ç§’å˜ä½
                frame_totals = method_data.groupby('TimeGroup')['TotalDurationPerFrame'].sum()
                frame_calls = method_data.groupby('TimeGroup')['Count'].sum()
            
            avg_duration = durations.mean()
            spike_threshold = avg_duration * spike_multiplier
            spike_records = method_data[method_data['Duration(ms)'] > spike_threshold]
            
            # Categoryåˆ—ãŒãªã„å ´åˆã¯æ¨å®š
            if 'Category' not in method_data.columns:
                category = self._extract_category(method_name)
            else:
                category = method_data['Category'].iloc[0]
            
            stats = {
                'MethodName': method_name,
                'Category': category,
                'TotalCalls': method_data['Count'].sum() if 'Count' in method_data.columns else len(method_data),
                'AvgDurationMs': avg_duration,
                'MaxDurationMs': durations.max(),
                'MinDurationMs': durations.min(),
                'StdDevMs': durations.std(),
                'FramesActive': len(frame_totals),
                'AvgTotalPerFrameMs': frame_totals.mean(),
                'MaxTotalPerFrameMs': frame_totals.max(),
                'SpikeCount': len(spike_records),
                'SpikeThreshold': spike_threshold,
                'AvgCallsPerFrame': frame_calls.mean(),
                'MaxCallsPerFrame': frame_calls.max(),
                'MinCallsPerFrame': frame_calls.min(),
                'AvgMemoryMB': method_data['MemoryMB'].mean() if 'MemoryMB' in method_data.columns else 0,
                'MaxMemoryMB': method_data['MemoryMB'].max() if 'MemoryMB' in method_data.columns else 0,
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
                'TotalImpactMs': frame_totals.sum(),
                'ImpactPercentage': 0,  # å¾Œã§è¨ˆç®—
                'PerformanceScore': avg_duration * (method_data['Count'].sum() if 'Count' in method_data.columns else len(method_data))  # å½±éŸ¿åº¦ã‚¹ã‚³ã‚¢
            }
            method_stats.append(stats)
        
        # DataFrameã«å¤‰æ›
        stats_df = pd.DataFrame(method_stats)
        
        # å½±éŸ¿åº¦ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’è¨ˆç®—
        total_impact = stats_df['TotalImpactMs'].sum()
        stats_df['ImpactPercentage'] = (stats_df['TotalImpactMs'] / total_impact * 100)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        stats_df = stats_df.sort_values('PerformanceScore', ascending=False)
        
        return stats_df
    
    def _extract_category(self, method_name):
        """ãƒ¡ã‚½ãƒƒãƒ‰åã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æ¨å®š"""
        if 'Manager' in method_name:
            return 'Manager'
        elif 'AI' in method_name:
            return 'AI'
        elif 'UI' in method_name:
            return 'UI'
        elif 'Render' in method_name or 'Graphics' in method_name:
            return 'Rendering'
        elif 'Audio' in method_name:
            return 'Audio'
        elif 'Network' in method_name:
            return 'Network'
        else:
            return 'Other'

    def frame_statistics(self):
        """ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆï¼ˆFPSè¨ˆç®—ã‚’å«ã‚€ï¼‰"""
        print("\nğŸ“ˆ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆä¸­...")
        
        frame_stats = []
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ãŸã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        if 'FrameCount' in self.df.columns:
            group_by_col = 'FrameCount'
            group_label = 'ãƒ•ãƒ¬ãƒ¼ãƒ '
        else:
            # æ–°MPSCãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã¯æ™‚é–“è»¸ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            self.df['TimeGroup'] = self.df['DateTime'].dt.floor('1S')  # 1ç§’å˜ä½
            group_by_col = 'TimeGroup'
            group_label = 'æ™‚é–“'
        
        for group_value, group_data in self.df.groupby(group_by_col):
            total_duration = group_data['TotalDurationPerFrame'].sum()
            top_methods = group_data.nlargest(5, 'TotalDurationPerFrame')[['Description', 'TotalDurationPerFrame']]
            
            # FPSè¨ˆç®—ï¼ˆæ¨å®šï¼‰: 1000ms / ãƒ•ãƒ¬ãƒ¼ãƒ ç·å‡¦ç†æ™‚é–“
            estimated_fps = 1000.0 / total_duration if total_duration > 0 else 60.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60FPS
            
            stats = {
                'FrameNumber': group_value,
                'FrameTime': group_data['DateTime'].iloc[0] if 'DateTime' in group_data.columns else None,
                'TotalFrameMs': total_duration,
                'EstimatedFPS': estimated_fps,
                'TotalCalls': group_data['Count'].sum() if 'Count' in group_data.columns else len(group_data),
                'UniqueMethodCount': len(group_data),
                'TotalMemoryMB': group_data['MemoryMB'].sum() if 'MemoryMB' in group_data.columns else 0,
                'TopMethod': top_methods.iloc[0]['Description'] if len(top_methods) > 0 else '',
                'TopMethodMs': top_methods.iloc[0]['TotalDurationPerFrame'] if len(top_methods) > 0 else 0
            }
            frame_stats.append(stats)
        
        return pd.DataFrame(frame_stats)

    def category_statistics(self):
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ"""
        print("\nğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆä¸­...")
        
        category_stats = []
        
        # Categoryåˆ—ãŒãªã„å ´åˆã¯Descriptionï¼ˆãƒ¡ã‚½ãƒƒãƒ‰åï¼‰ã‹ã‚‰æ¨å®š
        if 'Category' not in self.df.columns:
            self.df['Category'] = self.df['Description'].apply(self._extract_category)
        
        for category, category_data in self.df.groupby('Category'):
            durations = category_data['Duration(ms)']
            
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ãŸã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            if 'FrameCount' in self.df.columns:
                frame_totals = category_data.groupby('FrameCount')['TotalDurationPerFrame'].sum()
            else:
                # æ–°MPSCãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã¯æ™‚é–“è»¸ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                frame_totals = category_data.groupby(category_data['DateTime'].dt.floor('1S'))['TotalDurationPerFrame'].sum()
            
            stats = {
                'Category': category,
                'MethodCount': len(category_data['Description'].unique()),
                'TotalCalls': category_data['Count'].sum() if 'Count' in category_data.columns else len(category_data),
                'AvgDurationMs': durations.mean(),
                'MaxDurationMs': durations.max(),
                'StdDevMs': durations.std(),
                'TotalImpactMs': frame_totals.sum(),
                'AvgImpactPerFrameMs': frame_totals.mean(),
                'AvgMemoryMB': category_data['MemoryMB'].mean() if 'MemoryMB' in category_data.columns else 0
            }
            category_stats.append(stats)
        
        stats_df = pd.DataFrame(category_stats)
        return stats_df.sort_values('TotalImpactMs', ascending=False)

    def detect_performance_issues(self, method_stats):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã‚’æ¤œå‡º"""
        print("\nğŸš¨ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã‚’æ¤œå‡ºä¸­...")
        
        issues = []
        
        # é«˜è² è·ãƒ¡ã‚½ãƒƒãƒ‰ã®æ¤œå‡º
        high_impact = method_stats[method_stats['ImpactPercentage'] > 5.0]
        for _, method in high_impact.iterrows():
            issues.append({
                'Type': 'é«˜è² è·ãƒ¡ã‚½ãƒƒãƒ‰',
                'Method': method['MethodName'],
                'Issue': f"å…¨ä½“ã® {method['ImpactPercentage']:.1f}% ã‚’å ã‚ã‚‹é«˜è² è·",
                'Value': f"{method['AvgTotalPerFrameMs']:.2f}ms/frame",
                'Severity': 'HIGH' if method['ImpactPercentage'] > 10 else 'MEDIUM'
            })
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯å¤šç™ºãƒ¡ã‚½ãƒƒãƒ‰ã®æ¤œå‡º
        spike_methods = method_stats[method_stats['SpikeCount'] > 10]
        for _, method in spike_methods.iterrows():
            issues.append({
                'Type': 'ã‚¹ãƒ‘ã‚¤ã‚¯å¤šç™º',
                'Method': method['MethodName'],
                'Issue': f"{method['SpikeCount']} å›ã®ã‚¹ãƒ‘ã‚¤ã‚¯ç™ºç”Ÿ",
                'Value': f"æœ€å¤§ {method['MaxDurationMs']:.2f}ms",
                'Severity': 'HIGH' if method['SpikeCount'] > 50 else 'MEDIUM'
            })
        
        # å‘¼ã³å‡ºã—å›æ•°ç•°å¸¸ã®æ¤œå‡º
        call_variance = method_stats[
            (method_stats['MaxCallsPerFrame'] / method_stats['AvgCallsPerFrame'] > 3) &
            (method_stats['AvgCallsPerFrame'] > 1)
        ]
        for _, method in call_variance.iterrows():
            issues.append({
                'Type': 'å‘¼ã³å‡ºã—å›æ•°å¤‰å‹•',
                'Method': method['MethodName'],
                'Issue': f"æœ€å¤§ {method['MaxCallsPerFrame']:.0f} å›/frame (å¹³å‡ {method['AvgCallsPerFrame']:.1f})",
                'Value': f"å¤‰å‹•ç‡ {method['MaxCallsPerFrame']/method['AvgCallsPerFrame']:.1f}x",
                'Severity': 'MEDIUM'
            })
        
        return pd.DataFrame(issues)

    def generate_visualizations(self, method_stats, frame_stats, output_dir='analysis_output'):
        """å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        print(f"\nğŸ“Š å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆä¸­... ({output_dir}/)")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ãƒˆãƒƒãƒ—15ãƒ¡ã‚½ãƒƒãƒ‰ã®å½±éŸ¿åº¦
        plt.figure(figsize=(14, 8))
        top15 = method_stats.head(15)
        bars = plt.barh(range(len(top15)), top15['AvgTotalPerFrameMs'])
        plt.yticks(range(len(top15)), [name[:40] + '...' if len(name) > 40 else name for name in top15['MethodName']])
        plt.xlabel('å¹³å‡å½±éŸ¿åº¦ (ms/frame)')
        plt.title('CS1Profiler: ãƒˆãƒƒãƒ—15 é«˜è² è·ãƒ¡ã‚½ãƒƒãƒ‰')
        plt.gca().invert_yaxis()
        
        # ãƒãƒ¼ã«æ•°å€¤ã‚’è¡¨ç¤º
        for i, bar in enumerate(bars):
            width = bar.get_width()
            plt.text(width + 0.01, bar.get_y() + bar.get_height()/2, 
                    f'{width:.2f}ms', ha='left', va='center')
        
        plt.tight_layout()
        plt.savefig(f'{output_dir}/top15_methods.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥å½±éŸ¿åº¦ï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰
        category_stats = self.category_statistics()
        plt.figure(figsize=(10, 8))
        plt.pie(category_stats['TotalImpactMs'], labels=category_stats['Category'], autopct='%1.1f%%')
        plt.title('ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿åº¦')
        plt.savefig(f'{output_dir}/category_impact.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥è² è·æ¨ç§»ã¨FPS
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
        
        # ä¸Šæ®µ: ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†æ™‚é–“
        ax1.plot(frame_stats['FrameNumber'], frame_stats['TotalFrameMs'], alpha=0.7, label='å‡¦ç†æ™‚é–“')
        ax1.set_xlabel('ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·')
        ax1.set_ylabel('ç·å‡¦ç†æ™‚é–“ (ms)')
        ax1.set_title('ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥å‡¦ç†æ™‚é–“æ¨ç§»')
        ax1.grid(True, alpha=0.3)
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’å¼·èª¿è¡¨ç¤º
        spike_threshold = frame_stats['TotalFrameMs'].mean() + frame_stats['TotalFrameMs'].std() * 2
        spikes = frame_stats[frame_stats['TotalFrameMs'] > spike_threshold]
        if len(spikes) > 0:
            ax1.scatter(spikes['FrameNumber'], spikes['TotalFrameMs'], 
                       color='red', s=50, alpha=0.8, label=f'ã‚¹ãƒ‘ã‚¤ã‚¯({len(spikes)}å›)')
            ax1.legend()
        
        # ä¸‹æ®µ: æ¨å®šFPS
        ax2.plot(frame_stats['FrameNumber'], frame_stats['EstimatedFPS'], alpha=0.7, color='green', label='æ¨å®šFPS')
        ax2.set_xlabel('ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·')
        ax2.set_ylabel('æ¨å®šFPS')
        ax2.set_title('æ¨å®šFPSæ¨ç§»')
        ax2.grid(True, alpha=0.3)
        ax2.axhline(y=30, color='red', linestyle='--', alpha=0.7, label='30FPSé–¾å€¤')
        ax2.axhline(y=60, color='blue', linestyle='--', alpha=0.7, label='60FPSé–¾å€¤')
        ax2.legend()
        
        plt.tight_layout()
        plt.savefig(f'{output_dir}/frame_timeline_fps.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. ã‚¹ãƒ‘ã‚¤ã‚¯åˆ†æï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
        spike_methods = method_stats[method_stats['SpikeCount'] > 0].head(10)
        if len(spike_methods) > 0:
            plt.figure(figsize=(12, 6))
            plt.bar(range(len(spike_methods)), spike_methods['SpikeCount'])
            plt.xticks(range(len(spike_methods)), 
                      [name[:20] + '...' if len(name) > 20 else name for name in spike_methods['MethodName']], 
                      rotation=45, ha='right')
            plt.ylabel('ã‚¹ãƒ‘ã‚¤ã‚¯å›æ•°')
            plt.title('ãƒ¡ã‚½ãƒƒãƒ‰åˆ¥ã‚¹ãƒ‘ã‚¤ã‚¯ç™ºç”Ÿå›æ•° (Top10)')
            plt.tight_layout()
            plt.savefig(f'{output_dir}/spike_analysis.png', dpi=300, bbox_inches='tight')
            plt.close()

    def export_results(self, method_stats, frame_stats, issues, output_dir='analysis_output'):
        """è§£æçµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        print(f"\nğŸ’¾ è§£æçµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­... ({output_dir}/)")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # çµ±è¨ˆçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        method_stats.to_csv(f'{output_dir}/method_statistics.csv', index=False, encoding='utf-8-sig')
        frame_stats.to_csv(f'{output_dir}/frame_statistics.csv', index=False, encoding='utf-8-sig')
        issues.to_csv(f'{output_dir}/performance_issues.csv', index=False, encoding='utf-8-sig')
        
        # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        with open(f'{output_dir}/analysis_report.txt', 'w', encoding='utf-8') as f:
            f.write("CS1Profiler è§£æãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write("=" * 50 + "\n")
            f.write(f"è§£ææ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {self.csv_file}\n")
            f.write(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(self.df)}\n")
            if 'FrameCount' in self.df.columns:
                f.write(f"è§£æãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {self.df['FrameCount'].nunique()}\n")
            else:
                f.write(f"è§£ææ™‚é–“ç¯„å›²: {self.df['DateTime'].min()} ï½ {self.df['DateTime'].max()}\n")
            f.write(f"ç·ãƒ¡ã‚½ãƒƒãƒ‰æ•°: {self.df['Description'].nunique()}\n\n")
            
            # FPSçµ±è¨ˆ
            f.write("ğŸ“Š FPSçµ±è¨ˆ\n")
            f.write("-" * 30 + "\n")
            avg_fps = frame_stats['EstimatedFPS'].mean()
            min_fps = frame_stats['EstimatedFPS'].min()
            max_fps = frame_stats['EstimatedFPS'].max()
            fps_std = frame_stats['EstimatedFPS'].std()
            low_fps_frames = len(frame_stats[frame_stats['EstimatedFPS'] < 30])
            f.write(f"å¹³å‡FPS: {avg_fps:.1f}\n")
            f.write(f"æœ€ä½FPS: {min_fps:.1f}\n")
            f.write(f"æœ€é«˜FPS: {max_fps:.1f}\n")
            f.write(f"FPSæ¨™æº–åå·®: {fps_std:.1f}\n")
            f.write(f"30FPSæœªæº€ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {low_fps_frames} / {len(frame_stats)} ({low_fps_frames/len(frame_stats)*100:.1f}%)\n\n")
            
            # ãƒˆãƒƒãƒ—å•é¡Œ
            f.write("ğŸš¨ ä¸»è¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ\n")
            f.write("-" * 30 + "\n")
            for _, issue in issues.head(10).iterrows():
                f.write(f"[{issue['Severity']}] {issue['Type']}: {issue['Method']}\n")
                f.write(f"  è©³ç´°: {issue['Issue']} ({issue['Value']})\n\n")
            
            # ãƒˆãƒƒãƒ—ãƒ¡ã‚½ãƒƒãƒ‰
            f.write("ğŸ“Š é«˜è² è·ãƒ¡ã‚½ãƒƒãƒ‰ Top10\n")
            f.write("-" * 30 + "\n")
            for i, (_, method) in enumerate(method_stats.head(10).iterrows(), 1):
                f.write(f"{i:2d}. {method['MethodName']}\n")
                f.write(f"    å½±éŸ¿åº¦: {method['AvgTotalPerFrameMs']:.2f}ms/frame ({method['ImpactPercentage']:.1f}%)\n")
                f.write(f"    å‘¼ã³å‡ºã—: {method['TotalCalls']} å›, ã‚¹ãƒ‘ã‚¤ã‚¯: {method['SpikeCount']} å›\n\n")

    def run_full_analysis(self, output_dir='analysis_output'):
        """å®Œå…¨è§£æã‚’å®Ÿè¡Œ"""
        print("ğŸš€ CS1Profiler å®Œå…¨è§£æã‚’é–‹å§‹...")
        
        # çµ±è¨ˆç”Ÿæˆ
        method_stats = self.method_statistics()
        frame_stats = self.frame_statistics()
        issues = self.detect_performance_issues(method_stats)
        
        # å¯è¦–åŒ–
        self.generate_visualizations(method_stats, frame_stats, output_dir)
        
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        self.export_results(method_stats, frame_stats, issues, output_dir)
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        print("\n" + "="*60)
        print("ğŸ¯ CS1Profiler è§£æçµæœã‚µãƒãƒªãƒ¼")
        print("="*60)
        
        print(f"\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šä½5ãƒ¡ã‚½ãƒƒãƒ‰:")
        for i, (_, method) in enumerate(method_stats.head(5).iterrows(), 1):
            print(f"{i}. {method['MethodName'][:50]}")
            print(f"   {method['AvgTotalPerFrameMs']:.2f}ms/frame ({method['ImpactPercentage']:.1f}%)")
        
        print(f"\nğŸš¨ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ: {len(issues)} ä»¶")
        high_issues = issues[issues['Severity'] == 'HIGH']
        if len(high_issues) > 0:
            print("   é«˜é‡è¦åº¦å•é¡Œ:")
            for _, issue in high_issues.head(3).iterrows():
                print(f"   - {issue['Type']}: {issue['Method'][:40]}...")
        
        print(f"\nğŸ“ è©³ç´°çµæœ: {output_dir}/ ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        print("   - method_statistics.csv: ãƒ¡ã‚½ãƒƒãƒ‰åˆ¥çµ±è¨ˆ")
        print("   - frame_statistics.csv: ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥çµ±è¨ˆ") 
        print("   - performance_issues.csv: æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ")
        print("   - analysis_report.txt: è§£æãƒ¬ãƒãƒ¼ãƒˆ")
        print("   - *.png: å¯è¦–åŒ–ã‚°ãƒ©ãƒ•")

def main():
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ—¥æ™‚ãƒ™ãƒ¼ã‚¹ã«å¤‰æ›´
    default_output = f"analysis_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    parser = argparse.ArgumentParser(description='CS1Profiler CSV Analysis Tool')
    parser.add_argument('csv_file', help='CS1Profilerã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('-o', '--output', default=default_output, help=f'å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {default_output})')
    parser.add_argument('-s', '--spike-multiplier', type=float, default=2.0, help='ã‚¹ãƒ‘ã‚¤ã‚¯æ¤œå‡ºã®é–¾å€¤å€ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2.0)')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.csv_file):
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.csv_file}")
        return
    
    try:
        analyzer = CS1ProfilerAnalyzer(args.csv_file)
        analyzer.run_full_analysis(args.output)
        print(f"\nâœ… è§£æå®Œäº†! çµæœ: {args.output}/")
    except Exception as e:
        print(f"âŒ è§£æã‚¨ãƒ©ãƒ¼: {e}")
        raise

if __name__ == '__main__':
    main()
